{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b486e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295b9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANR = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eb8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3dfde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_part(corpus, all_corpus):\n",
    "    all_texts = ' '.join(corpus)\n",
    "    lem_words = m.lemmatize(all_texts)\n",
    "    for txt in lem_words:\n",
    "        if txt != '\\n' and txt.strip() != '':\n",
    "            all_corpus.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3468767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq(data):\n",
    "    word_freq = defaultdict(int)\n",
    "    for token in data:\n",
    "        word_freq[token] += 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d75206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_column(column_name):\n",
    "    corpus = []\n",
    "    all_corpus = []\n",
    "    for index, row in df.iterrows():\n",
    "        words = row[column_name]\n",
    "        if pd.notnull(words):\n",
    "            words = words.lower()\n",
    "            words = cleanhtml(words)\n",
    "            words = tokenizer.tokenize(words)\n",
    "            text = ' '.join(\n",
    "                [word for word in words if not word.isdigit() and word not in set(stopwords.words('russian'))])\n",
    "            corpus.append(text)\n",
    "            if index > 0 and index % 100 == 0:\n",
    "                lemm_part(corpus, all_corpus)\n",
    "                corpus = []\n",
    "    lemm_part(corpus, all_corpus)\n",
    "    return all_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64616ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', encoding='UTF-8')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5319312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_lemm = lemm_column('cond')\n",
    "cond_count = len(cond_lemm)\n",
    "cond_result = count_freq(cond_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "137069fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_lemm = lemm_column('req')\n",
    "req_result = count_freq(req_lemm)\n",
    "req_count = len(req_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89b705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_lemm = lemm_column('resp')\n",
    "resp_result = count_freq(resp_lemm)\n",
    "resp_count = len(resp_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b61fff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count = cond_count + req_count + resp_count\n",
    "\n",
    "cond_data = pd.DataFrame(\n",
    "    cond_data = pd.DataFrame(\n",
    "    columns=['word', 'count_in_condition', 'count_in_requirements',\n",
    "             'count_in_responsibilities', 'frequency_in_condition',\n",
    "             'frequency_in_requirements', 'frequency_in_responsibilities'])\n",
    "for word, count in cond_result.items():\n",
    "    c_c = count\n",
    "    rq_c = req_result.pop(word, 0)\n",
    "    rs_c = resp_result.pop(word, 0)\n",
    "\n",
    "    c_all = c_c + rq_c + rs_c\n",
    "    c_f = c_c / c_all\n",
    "    rq_f = rq_c / c_all\n",
    "    rs_f = rs_c / c_all\n",
    "    new_row_data = {'word': word, 'count_in_condition': c_c, 'count_in_requirements': rq_c,\n",
    "                    'count_in_responsibilities': rs_c,\n",
    "                    'frequency_in_condition': c_f,\n",
    "                    'frequency_in_requirements': rq_f,\n",
    "                    'frequency_in_responsibilities': rs_f}\n",
    "    new_row = pd.DataFrame([new_row_data])\n",
    "    cond_data = pd.concat([cond_data, new_row], ignore_index=True)\n",
    "for word, count in req_result.items():\n",
    "    rq_c = count\n",
    "    rs_c = resp_result.pop(word, 0)\n",
    "\n",
    "    c_all = rq_c + rs_c\n",
    "    rq_f = rq_c / c_all\n",
    "    rs_f = rs_c / c_all\n",
    "    new_row_data = {'word': word, 'count_in_condition': 0, 'count_in_requirements': rq_c,\n",
    "                    'count_in_responsibilities': rs_c,\n",
    "                    'frequency_in_condition': 0,\n",
    "                    'frequency_in_requirements': rq_f,\n",
    "                    'frequency_in_responsibilities': rs_f}\n",
    "    new_row = pd.DataFrame([new_row_data])\n",
    "    cond_data = pd.concat([cond_data, new_row], ignore_index=True)\n",
    "\n",
    "for word, count in resp_result.items():\n",
    "    rs_c = count\n",
    "    new_row_data = {'word': word, 'count_in_condition': 0, 'count_in_requirements': 0,\n",
    "                    'count_in_responsibilities': rs_c,\n",
    "                    'frequency_in_condition': 0,\n",
    "                    'frequency_in_requirements': 0,\n",
    "                    'frequency_in_responsibilities': rs_f}\n",
    "    new_row = pd.DataFrame([new_row_data])\n",
    "    cond_data = pd.concat([cond_data, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5704559",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_data['condition_freq_count'] = cond_data['count_in_condition'] * cond_data['frequency_in_condition']\n",
    "cond_data['requirements_freq_count'] = cond_data['count_in_requirements'] * cond_data['frequency_in_requirements']\n",
    "cond_data['responsibilities_freq_count'] = cond_data['count_in_responsibilities'] * cond_data['frequency_in_responsibilities']\n",
    "cond_data.to_csv('word_frequencies.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d573821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_column(column_name, n):\n",
    "    ex_words = {'и', 'или', 'также', 'так', 'же', 'а'}\n",
    "    corpus = []\n",
    "    unique_data = df[['ad_id', column_name]]\n",
    "    unique_data = unique_data.drop_duplicates()\n",
    "    for index, row in unique_data.iterrows():\n",
    "        words = row[column_name]\n",
    "        if pd.notnull(words):\n",
    "            words = words.lower()\n",
    "            words = cleanhtml(words)\n",
    "            for w in ast.literal_eval(words):\n",
    "                tokens = tokenizer.tokenize(w)\n",
    "                cleaned_tokens = [t for t in tokens if t not in ex_words]\n",
    "                n_grams = ngrams(cleaned_tokens, n)\n",
    "                text = [' '.join(grams) for grams in n_grams]\n",
    "                corpus.extend(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc40fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b20ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngramm(n):\n",
    "    cond_lemm = ngram_column('cond', n)\n",
    "    cond_count = len(cond_lemm)\n",
    "    cond_result = count_freq(cond_lemm)\n",
    "    req_lemm = ngram_column('req', n)\n",
    "    req_result = count_freq(req_lemm)\n",
    "    req_count = len(req_lemm)\n",
    "    resp_lemm = ngram_column('resp', n)\n",
    "    resp_result = count_freq(resp_lemm)\n",
    "    resp_count = len(resp_lemm)\n",
    "    cond_data = pd.DataFrame(\n",
    "        columns=['word', 'count_in_condition', 'count_in_requirements',\n",
    "                 'count_in_responsibilities', 'frequency_in_condition', 'frequency_in_requirements',\n",
    "                 'frequency_in_responsibilities'])\n",
    "    for word, count in cond_result.items():\n",
    "        c_c = count\n",
    "        rq_c = req_result.pop(word, 0)\n",
    "        rs_c = resp_result.pop(word, 0)\n",
    "\n",
    "        c_all = c_c + rq_c + rs_c\n",
    "        c_f = c_c / c_all\n",
    "        rq_f = rq_c / c_all\n",
    "        rs_f = rs_c / c_all\n",
    "        new_row_data = {'word': word, 'count_in_condition': c_c, 'count_in_requirements': rq_c,\n",
    "                        'count_in_responsibilities': rs_c, 'frequency_in_condition': c_f,'frequency_in_requirements':rq_f, 'frequency_in_responsibilities':rs_f}\n",
    "        new_row = pd.DataFrame([new_row_data])\n",
    "        cond_data = pd.concat([cond_data, new_row], ignore_index=True)\n",
    "\n",
    "    for word, count in req_result.items():\n",
    "        rq_c = count\n",
    "        rs_c = resp_result.pop(word, 0)\n",
    "\n",
    "        c_all = rq_c + rs_c\n",
    "        rq_f = rq_c / c_all\n",
    "        rs_f = rs_c / c_all\n",
    "        new_row_data = {'word': word, 'count_in_condition': 0, 'count_in_requirements': rq_c,\n",
    "                        'count_in_responsibilities': rs_c, 'frequency_in_condition': 0,\n",
    "                        'frequency_in_requirements': rq_f, 'frequency_in_responsibilities': rs_f}\n",
    "        new_row = pd.DataFrame([new_row_data])\n",
    "        cond_data = pd.concat([cond_data, new_row], ignore_index=True)\n",
    "\n",
    "    for word, count in resp_result.items():\n",
    "        rs_c = count\n",
    "        new_row_data = {'word': word, 'count_in_condition': 0, 'count_in_requirements': 0,\n",
    "                        'count_in_responsibilities': rs_c, 'frequency_in_condition': 0,\n",
    "                        'frequency_in_requirements': 0, 'frequency_in_responsibilities': 1}\n",
    "        new_row = pd.DataFrame([new_row_data])\n",
    "        cond_data = pd.concat([cond_data, new_row], ignore_index=True)\n",
    "\n",
    "    cond_data['condition_freq_count'] = cond_data['count_in_condition'] * cond_data['frequency_in_condition']\n",
    "    cond_data['requirements_freq_count'] = cond_data['count_in_requirements'] * cond_data['frequency_in_requirements']\n",
    "    cond_data['responsibilities_freq_count'] = cond_data['count_in_responsibilities'] * cond_data['frequency_in_responsibilities']\n",
    "\n",
    "    cond_data.to_csv(str(n) + 'gramm_frequencies.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21d14178",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ngramm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8df85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ngramm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a01f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ngramm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f1bb84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ngramm(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02445501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers_to_excel(file_name):\n",
    "    df = pd.read_csv(file_name, encoding='UTF-8')\n",
    "    df.to_csv('excel_' + file_name, encoding='utf8', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b471ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_numbers_to_excel('word_frequencies.csv')\n",
    "convert_numbers_to_excel('2gramm_frequencies.csv')\n",
    "convert_numbers_to_excel('3gramm_frequencies.csv')\n",
    "convert_numbers_to_excel('4gramm_frequencies.csv')\n",
    "convert_numbers_to_excel('5gramm_frequencies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b2785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
